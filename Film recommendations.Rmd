---
title: "Итоговый проект"
author: "Группа 9"
output: 
  html_document:
    code_folding: hide
---

В этом исследовании мы предприняли попытку создать эффективные рекомендательные системы для платформы, которые могут помочь пользователям найти фильмы, соответствующие их предпочтениям. Мы использовали комбинацию методов, включая сетевой анализ, текстовый и сентимент-анализ, а также рекомендательные системы, чтобы создать модели, которые могут прогнозировать предпочтения пользователей.

**Целью** нашего исследования является создание эффективных рекомендательных систем для фильмов, которые могут прогнозировать предпочтения пользователей и помочь им найти фильмы, соответствующие их интересам.

В этом исследовании мы использовали следующие **методы**:

1. **Сетевой анализ**: для изучения структуры данных и определения сообществ внутри фильмов с различными характеристиками.
2. **Текстовый анализ**: для определения наиболее используемых тегов, эмоциональной тональности текстов и понимания, какие фильмы наиболее популярны среди пользователей.
3. **Рекомендательные системы**: для создания систем, которые могут прогнозировать предпочтения пользователей и помочь им найти фильмы, соответствующие их интересам.

В этом проекте мы выполним следующие **шаги**:

1. **Сетевой анализ**: мы сравним различные методы выделения сообществ и выберем наилучший, а также создадим ультимативную рекомендацию для пользователей, у которых еще нет выраженных предпочтений.
2. **Сентимент-анализ**: мы определим самые популярные теги и самые восторженные отзывы о фильмах.
3. **Рекомендательные системы**: мы создадим две рекомендательные системы: Collaborative Filtering и Content-based, и оценим их на релевантность на примерах и по объективным метрикам.
4. **Оценка результатов**: мы оценим результаты наших рекомендательных систем и сравним их с результатами других методов.


В этом исследовании мы ожидаем, что наши рекомендательные системы будут иметь хорошие прогностические способности для пользователей разных категорий. Мы также ожидаем, что наши методы будут полезны для понимания структуры данных и для определения смысловой наполненности текстов.


Сначала опишем имеющиеся переменные. 

Переменные:

`metadata`

* title -- название
* directedBy -- режиссер
* starring -- актеры
* avgRating -- средняя оценка на MovieLens
* imdbId -- id на IMDb
* item_id -- id фильма

`survey_answers`
* item_id -- id фильма
* user_id -- id пользователя
* tag_id -- id тега
* score -- уверенность пользователя в соответствии тега фильму

`tags`
* tag -- сам тег
* id -- id тега


Переменные:

* item_id -- id фильма, которому поставлена оценка
* user_id -- id пользователя, поставившего оценку
* rating -- оценка

### Предобработка 
Загрузим данные:

```{r message = FALSE, warning=FALSE}
library (dplyr)
library(stringr)
library (tidyr)
library(igraph)
library(tnet)
library(ggplot2)
library(tidytext)
library(recommenderlab)
library(tidyverse)
load("~/shared/minor2_2023/data/project/metadata_g_9.RData")
load("~/shared/minor2_2023/data/project/ratings_g_9.RData")
```


**Сетевой анализ**

Первым делом мы провели сетевой анализ, чтобы лучше ознакомиться со структурой данных. 

Поскольку мы планируем использовать теги как основу для группировки фильмов, следует избавиться от тегов, которые встречаются лишь один раз, так как на их основе не получится найти связь между тегами. Проведем обработку данных и посмотрим на возможные сообщества согласно тегам фильмов. 

Для анализа структуры сообществ в сетевых данных были применены несколько популярных алгоритмов:
1) Жадный алгоритм (Fast Greedy): Этот алгоритм последовательно объединяет сообщества, которые максимизируют модулярность. Он показал разбиение данных на 10 сообществ.

2) Алгоритм Walktrap: Данный алгоритм основан на идее, что случайные блуждания на графе с высокой вероятностью останутся внутри одного сообщества. Он выделил 69 сообществ, что кажется несколько нерелевантным.

3) Многоуровневая оптимизация модулярности: Этот метод иерархически объединяет сообщества, чтобы максимизировать модулярность. Он оказался наиболее эффективным, разделив данные на 12 сообществ. 

```{r message = FALSE, warning=FALSE}
# Группируем теги по количеству повторений и фильтруем теги, встречающиеся более одного раза
repeated_tags <- survey_answers %>% 
  group_by(tag_id) %>%
  count() %>%
  filter(n > 1) %>%
  select(-n)

# Объединяем данные по тегам, встречающимся более одного раза
tagged_answ <- inner_join(survey_answers, repeated_tags)
tagged_films <- inner_join(tagged_answ, metadata) %>%
  select(item_id, tag_id) %>%
  mutate(values_from = 1)

# Создаем матрицу смежности
adj_m <- pivot_wider(tagged_films, names_from = tag_id, values_from = values_from)
adj_m <- adj_m %>% mutate(across(everything(), ~replace(., lengths(.)==0, 0)))

# Группируем теги по фильмам, фильтруем теги, встречающиеся более одного раза в одном фильме
tagged_films <- tagged_films %>% 
  group_by(item_id, tag_id) %>%
  count() %>%
  filter(n > 1) %>%
  arrange(tag_id)

# Избавимся от дублей тегов в одном фильме
tagged_films <- tagged_films %>%
  distinct(item_id, tag_id)


# Заменяем строковые значения на 1
adj_m <- adj_m %>%
  mutate(across(everything(), ~ifelse(. %in% c("c(1, 1)", "c(1, 1, 1)"), 1, .)))

# Преобразуем в data.frame и устанавливаем rownames
adj_m <- as.data.frame(adj_m)
rownames(adj_m) <- adj_m$item_id

# Удаляем столбец item_id и преобразуем в матрицу
adj_m <- adj_m %>% select(-item_id) %>% as.matrix()

# Создаем граф из матрицы смежности
graph <- graph_from_incidence_matrix(adj_m)

# Проецируем двухмодальный граф в одномодальный
projections <- bipartite.projection(graph)
projection <- projections[[1]]

# Применяем алгоритм Fast Greedy для выделения сообществ
greedy_comm <- fastgreedy.community(projection)

# Сортируем членство в сообществах и выводим результаты
x <- sort(greedy_comm$membership)
table(greedy_comm$membership)

# Применяем алгоритм Walktrap для выделения сообществ
walktrap_comm <- walktrap.community(projection)
a <- sort(walktrap_comm$membership)
table(walktrap_comm$membership)

# Вычисляем модулярность для алгоритмов
modularity_wc <- modularity(walktrap_comm, projection)
modularity_gc <- modularity(greedy_comm, projection)

# Применяем алгоритм многоуровневой оптимизации модулярности
community_structure <- multilevel.community(projection)
sorted_membership <- sort(community_structure$membership)
table(community_structure$membership)
modularity_sc <- modularity(community_structure, projection)

item_ids_memb = as.numeric(community_structure$names)
membership_ids = as.numeric(community_structure$membership)
memb = data.frame(item_ids_memb, membership_ids)
names(memb)[names(memb) == 'item_ids_memb'] <- 'item_id'
# Заметим, что наиболее эффективным методом разбиения данных на сообщества оказался метод многоуровневой оптимизации модулярности: он не передробил данные на слишком мелкие части и при этом является достаточно репрезентативным для изучения структуры данных 
```
Таким образом, наиболее оптимальным методом разбиения данных на сообщества оказался алгоритм многоуровневой оптимизации модулярности, который показал наибольшее значение модулярности и при этом не дробил данные на слишком мелкие части. Этот метод будет использован для дальнейшего анализа структуры сообществ в сетевых данных.

Составим еще корпус фильмов, которые могут быть полезны для рекомендации людям, у которых не сформировались четкие предпочтения. 
Как нам кажется, рекомендовать фильмы просто с самым высоким рейтингом может быть не очень правильно в таком случае, потому что они могут быть крайне узкоспециализированными/камерными и могут понравиться только тем, у кого очень специфический вкус, что и сформирует высокий рейтинг при низкой популярности. 

Поэтому можно посмотреть на другие метрики. Сделаем отдельный датафрейм с айди фильма и количеством оставленных отзывов, а также рейтингом. Это может быть полезно для анализа популярности фильмов, выявления трендов и рекомендации фильмов пользователям на основе их центральности в сети отзывов.

```{r message = FALSE, warning=FALSE}
library(dplyr)

library(dplyr)

reviews_summary <- ratings %>%
  group_by(item_id) %>%
  summarize(num_reviews = n()) %>%
  left_join(ratings, by = "item_id") %>%
  group_by(item_id) %>%
  summarize(
    weighted_sum = sum(rating * n()),
    total_reviews = sum(n())
  ) %>%
  mutate(weighted_avg_rating = weighted_sum / total_reviews)

print(reviews_summary)
```
```{r message = FALSE, warning=FALSE}
library(igraph)

reviews_graph <- graph_from_data_frame(reviews_summary)

degree_centrality <- centr_degree(reviews_graph, mode = "all", normalized = TRUE)$res

reviews_summary$degree_centrality <- degree_centrality[match(reviews_summary$item_id, V(reviews_graph)$name)]

films_ranked <- reviews_summary %>%
  arrange(desc(degree_centrality))

print(films_ranked)
```
Теперь составим ультимативный список рекомендованных фильмов для просмотра:

```{r message = FALSE, warning=FALSE}
movies_ranked <- metadata %>%
  inner_join(films_ranked, by = "item_id") %>%
  filter(degree_centrality == 2) %>%
  select(title)
```
Эти результаты будут использованы в дальнейшем:) 

Таким образом, в ходе сетевого анализа мы глубже рассмотрели структуру данных, что, однако, в последующей части проекта не нашло применения. Однако мы воспользовались инструментом определения центральности для составления рекомендации для разных категорий пользователей. 

### Текстовый анализ


1)Сначала определим, какие тэги зрители оценили выше всего и выведем топ 15-тэгов
```{r message = FALSE, warning=FALSE}
#хочу обьединить некоторые сеты для удобного исследования
a = metadata %>% select(title, directedBy, starring, item_id, avgRating)
tags$tag_id = tags$id
b = merge(survey_answers, tags, by = "tag_id") %>% select(-id)
c = merge(b,ratings, by = "user_id")#отсюда видно, что пользователи сами пишут один и тот же тэг к разным фильмам(item_id.y), и ставят этим разным фильмам разные оценки, то есть ЕСТЬ ГРУППЫ ПО ТЭГАМ
#кроме того видно что тэги в некотором роде не уникальны и есть от одного пользователя 10 тэгов "zombies", а от другого 15 "zombie"
#поэтому есть смысл в ЛЕММАТИЗАЦИИ  тэгов. Однако стоит обратить внимание, что не все тэги с одинаковым смысловым значением мы програмно можем отнести к одному, так напрмер "world war ii" b "wwii" придется воспринимать как два разных смысловых тэга

library(textstem)
c$tag = c$tag %>% stem_words(words, language = "en")

#далее проверим какие оценки выставлют в среднем(или не в среднем, если тут только этот тэг от одного пользователя) с учетом уверенности в тэге (от 3) и без учета уверенности и сравним
q1 = c %>% group_by(tag) %>% summarise(all = mean(rating))
q2 = c %>% filter(score >=3) %>% group_by(tag) %>% summarise(with_score_in_view = mean(rating))
#сделаем табличку где наглядно сравним нужно ли учитывать уверенность в выставлении оценки 
q = left_join(q1,q2,by = "tag")
#вынесем среднюю оценку из двух показателей(где есть оба), или только all-оценку
q$final_mark  =  case_when(
    is.na(q$with_score_in_view) ~ q$all,  # Если значение во втором столбце NA, то берется значение из первого столбца
    TRUE ~ (q$with_score_in_view + q$all) / 2  # Иначе берется среднее значение
  )
#теперь выведем топ 15 тэгов по оценкам пользователей
top_tags = q %>% arrange(desc(final_mark)) %>% head(15)

```
Далее можно выгрузить список фильмов с данными тэгами и обеспечить пользователя хорошими, по мнению других экспертов, фильмами. 
Также полученный результат может быть полезен, если есть спор между выбором темы фильма, что позволяет  обратиться к данному списку и узнать, какая тема из предложенных оценивается наилучшим образом, и, следовательно, что лучше предпочесть.

!Кроме того, видно что уверенность оценки(score) можно не учитывать так как оценка по all и по with_score_in_view в общем случае мало различны. Это знание применим в будущем.

2) Выведем по одному лучшему фильму из среди каждого тэга 
Для этого будем использовать оценку(rating), данную самими пользователями
```{r message = FALSE, warning=FALSE}
c = c %>% select(-item_id.x) %>% rename("item_id" = item_id.y)
big_data = merge(c,a, by = "item_id") #это важный дата сет, так как здесь видно много информации: все тэги(лемматизированные) к одному фильму, оценка пользователя, оценка на MovieLens

best_tag_film = big_data %>% group_by(tag) %>% slice(which.max(rating)) 
```


3) Давайте рассмотрим сентимент анализ, поссмотрим, какие из фильмов можно отнести к положительным или отрицательным на основе набора тэгов к тому или иному фильму.
Будем использовать: AFINN.
Это словарь, предоставляющий оценки тональности слов на шкале от -5 (негативный) до +5 (позитивный). Этот словарь может быть использован для анализа тональности текста на основе суммирования оценок для каждого слова.
```{r message = FALSE, warning=FALSE}
options(timeout = 300)
options(repos = c(CRAN = "https://cloud.r-project.org"))

install.packages("dplyr", reinstall = TRUE)
install.packages("textdata", reinstall = TRUE)

install.packages("textdata")
library(textdata)
install.packages("tidytext")
library(tidytext)

afinn_sent = get_sentiments("afinn")
afinn_sent = afinn_sent %>% rename("tag" = word)
big_data = merge(big_data,afinn_sent)

data_nastr = big_data %>% group_by(title) %>% summarise(nastroenie = mean(value)) %>% arrange(desc(nastroenie))
```
Так мы получили список фильмов с наиболее красочным описанием, преобладающей позитивной окраской в описании фильма.

## Рекомендательная система: метод коллаборативной фильтрации

Для коллаборативной фильтрации мы будем использовать метод IBCF, потому что мы имеем всего 500 фильмов в датасете, а пользователей больше - около 3000. Поэтому будет целесообразнее сравнивать похожесть фильмов из-за того, что у фильмов много оценок, а у пользователей немного, т.к. много пользователей ставят много оценок, а из-за малого количества фильмов у пользователей мало оценок. Наша система будет работать следующим образом: для каждого пользователя мы извлечем фильмы, которые он оценил, для каждого из этих фильмов найдем похожие. При рекомендации фильтры упорядочиваются на основе весов, где вес каждой рекомендации вычисляется на основе оценок пользователя и показателей схожести фильмов (взвешенной суммы).

```{r message = FALSE, warning=FALSE}
rates = pivot_wider(ratings, names_from = item_id, values_from = rating) # Преобразуем данные по рейтингу фильмов в формат realRatingMatrix, этот формат понятен пакету recommenderlab. До этого преобразуем данные в широкий формат, а затем в обычную матрицу.
userNames = rates$user_id
rates = select(rates, -user_id)
rates = as.matrix(rates)
rownames(rates) = userNames
r = as(rates, "realRatingMatrix", strict = T)
```


Теперь подготоим данные и уберем нерелевантные данные. Например, фильмы, у которых мало оценок, и пользователей, которые мало фильмов оценили. В таких случаях может происходить смещение в силу малого количества данных, из-за чего может неправильно определиться похожесть.
Построим графики, показывающие количество оценок у одного пользователя и у одного фильма.


Для того, чтобы определить точки по которым мы отсечем количество оценок у пользователя и у фильма построим функцию оценки формальных метрик IBCF модели при различных точках отсечения, затем найдем оптимальные точки.
```{r message = FALSE, warning=FALSE}
eval_schemes = function(new_ratings) {
set.seed(333)
eval_sets <- evaluationScheme(data = new_ratings, 
                              method = "split",
                              train = 0.7, # разделили 30/70
                              given = 10, # у нас отфильтровано более 10 оценок
                              goodRating = 4) # если предсказанная оценка < 4, то фильм не рекомендуем

model <-
  Recommender(data = getData(eval_sets, "train"), method = "IBCF")

pred_rec <-
  predict(
    object = model,
    newdata = getData(eval_sets, "known"),
    n = 5,
    type = "ratings"
  )

eval_accuracy <- calcPredictionAccuracy(
      x = pred_rec,
      data = getData(eval_sets, "unknown"),
      byUser = F
)

return(eval_accuracy)
}

eval_list <- c()
lens = length(eval_list)
for (i in 10:20) {
  for (j in 10:20) {
    movies_ratings_test <- r[rowCounts(r) > i, colCounts(r) > j]
    eval_list[[lens+1]] <- eval_schemes(movies_ratings_test)
    eval_list[[lens+1]][[4]] <- i
    eval_list[[lens+1]][[5]] <- j
    lens = length(eval_list)
  }
}
min1 = 100
min2 = 100
min3 = 100
for (i in 1:121) {
  if (eval_list[[i]][[1]] < min1) {
    min1_n = c(eval_list[[i]][[4]], eval_list[[i]][[5]])
  }
  if (eval_list[[i]][[2]] < min2) {
    min2_n = c(eval_list[[i]][[4]], eval_list[[i]][[5]])
  }
  if (eval_list[[i]][[3]] < min3) {
    min3_n = c(eval_list[[i]][[4]], eval_list[[i]][[5]])
  }
}
print("RMSE")
print(min1_n)
print("MSE")
print(min2_n)
print("MAE")
print(min3_n)
```
Для того, чтобы минимизировать RMSE, MSE и MAE, следует выбрать фильмы, у которых более 20 оценок, а также пользователей, которые оценили более 20 фильмов.
```{r message = FALSE, warning=FALSE}
ggplot(data = data.frame(filmRate=colCounts(r))) + geom_histogram(aes(x=filmRate)) + geom_vline(xintercept = 20, c="red")
ggplot(data = data.frame(userRate=rowCounts(r))) + geom_histogram(aes(x=userRate)) + geom_vline(xintercept = 20, c="red")
```


```{r message = FALSE, warning=FALSE}
movies_ratings <- r[rowCounts(r) > 20, colCounts(r) > 20]
```

Теперь перейдем к самой модели. Разделим нашу выборку на обучающую и тестовую. На обучающей выборке обучаем модель, на тестовой будем проверять модель.
```{r message = FALSE, warning=FALSE}
set.seed(333)
test_ind <- sample(1:nrow(movies_ratings), size = nrow(movies_ratings)*0.3) # 30% на тестовую выборку
recc_train <- movies_ratings[-test_ind, ]
recc_test <- movies_ratings[test_ind, ]
```

Мы используем метод IBCF для рекомендательной системы. Теперь обучаем нашу рекомендательную систему и оформляем ее в виде функции. Модель будет выдавать топ 5 фильмов. Важно что функция будет выдавать не id фильмов, а их названия, это будет реализовано с помощью функции match().
```{r message = FALSE, warning=FALSE}
model <- Recommender(data = recc_train, method = "IBCF")
pred_rec<- predict(object = model, newdata = movies_ratings, n = 5)
names(pred_rec@items) = rownames(movies_ratings)
ibcf_getfilms = function(id = ""){
if (sum(rownames(movies_ratings) == id) > 0) {
user_rec <- pred_rec@items[[id]]
user_movies <- pred_rec@itemLabels[user_rec]
user_movies_labels <- metadata$title[match(user_movies, metadata$item_id)]
return(user_movies_labels)} else {
  return(movies_ranked$title)}
}
```

Для формальной оценки модели будем использовать показатели MSE, MAE и RMSE.
```{r message = FALSE, warning=FALSE}
eval_schemes(movies_ratings) # функция для оценки метрик, которую мы создали ранее
```

**Оценка рекоммендации:** Исходя из представленных метрик, можно сказать, что c помощью перебора точек отсечения количества отзывов удалось минимизировать RMSE, MSE и MAE. Таким образом, можно говорить о состоятельности данной рекоммендательной системы, которая будет также проверена ниже с помощью примеров.

##### Примеры

Рассмотрим примеры, чтобы более точно оценить адекватность рекоммендательной системы. Для этого создадим список фильмов, понравившихся пользователю, т. е. с оценкой выше 4, а затем сравним их с фильмами, рекомендованными данному пользователю. 

Выберем пользователя с id "14379".

```{r message = FALSE, warning=FALSE}
sort_films1 = ratings %>% dplyr::filter(user_id==627711) %>% dplyr::filter(rating>=4.0)
fav_films1= metadata$title[match(sort_films1$item_id, metadata$item_id)]
fav_films1
```
Список включает фильмы разных жанров - драмы, триллеры, комедии, супергеройские блокбастеры и другие.

```{r message = FALSE, warning=FALSE}
ibcf_getfilms("627711")

```
Поэтому ему были рекомендованы фильмы также разных жанров - боевик, триллер, комедия, драма. Это демонстрирует разнообразие кинематографических произведений, которые могут быть интересны этому пользователю. 

Теперь посмотрим на пользователя "41783". 
```{r message = FALSE, warning=FALSE}
sort_films2 = ratings %>% dplyr::filter(user_id==41783) %>% dplyr::filter(rating>=4.0)
fav_films2= metadata$title[match(sort_films2$item_id, metadata$item_id)]
fav_films2
```
Ему понравились фильмы в жанре научной фантастики, а также фильмы-приключения, боевики, триллеры и драмы.

Посмотрим, какие фильмы будут предложены:
```{r message = FALSE, warning=FALSE}
ibcf_getfilms("41783")

```
В результате, ему были рекомендованы фильм-приключение "The Mask of Zorro" и научная фантастика "The fifth element", а также триллер "The others", что совпадает с фильмами, которые понравились пользлвателю.

Также рассмотрим пример, когда мы используем пустую функцию:
```{r message = FALSE, warning=FALSE}
ibcf_getfilms()
```
Как видно, если пользователь не вводит свой id и запускает пустую функцию, то ему будет выдаваться список с наиболее популярными среди других пользователей фильмами, отобранных нами в ходе сетевого анализа.


## Рекомендательная система: content-based

Content-based система основывается на схожести фильма по следующим признакам: средняя оценка фильма на MovieLens, средняя оценка фильма, посчитанная по нашим данным, принадлежность к сообществам в сети тегов, а также тональность фильма, выделенная по названиям с помощью текстового анализа. Для каждого id пользователя система отбирает фильмы, которые он оценил от 4 и которые схожи по выделенным признакам с оцененными им фильмами. Рекомендательная система выводит 5 наиболее подходящих для пользователя фильмов.

Вычислим средние оценки для каждого фильма.
```{r message = FALSE, warning=FALSE}
mean_ratings = ratings %>% group_by(item_id) %>% summarise(mean_user_rating=mean(rating))
```

Создадим датасет, в котором соединим данные по фильмам, их средним оценкам, принадлежности фильма к определенному сообществу, а также по тональности. Потом исключим из датасета все переменные, которые не понадобятся при построении рекомендтельной системы (название, режиссер, актеры, средний рейтинг, id IMDb)
```{r message = FALSE, warning=FALSE}
rownames=metadata$item_id
data=inner_join(metadata, mean_ratings)
metadata2=metadata%>%select(-title, -directedBy, -starring, -avgRating, -imdbId)
metadata2$item_id=as.numeric(metadata$item_id)
data=inner_join(data, metadata2)
data=inner_join(data, memb) #тут мы используем разбиение на сообщества, полученное при помощи метода многоуровневой оптимизации модулярности
data = inner_join(data, data_nastr)
rownames(data)=data$item_id
rating2 = left_join(data, ratings)
data=data%>%select(-item_id, -title, -directedBy, -starring, -imdbId)
```

Будем вычислять похожесть с помощью косинусного расстояния. Чтобы не рекомендовать одни и те же фильмы, заменим значения на диагонали на 0.
```{r message = FALSE, warning=FALSE}
cos = lsa::cosine(t(as.matrix(data)))
diag(cos) = 0
```
Оформим рекомендательную систему в виде функции: отберем id фильмов с оценкой более 4, чтобы рекомендовать только относительно хорошие фильмы; выведем 5 фильмов, наиболее похожих на те, что оценил пользователь.
```{r}
getFilms = function(userId=""){
  if (sum(rating2$user_id == userId) > 0) {
  user = rating2 %>% filter(user_id == userId & rating >= 4)
    mostSimilar3 = head(sort(cos[,as.character(user$item_id)], decreasing = T), n = 5)
    a = which(cos[,as.character(user$item_id)] %in% mostSimilar3, arr.ind = TRUE)
    index = arrayInd(a, .dim = dim(cos[,as.character(user$item_id)]))
    result = rownames(cos)[index[,1]]
    recommend = filter(metadata, item_id %in% result) %>% dplyr::select(title)
  
  recommend} else {
    return(movies_ranked$title)
  }
}
```


**Оценка рекоммендации:** Для оценки качества рекоммендательной системы ниже будут рассмотрены примеры её применения.

#### Примеры 

Для более удобного поиска примеров, объединим в один датасет id пользователя и названия фильмов. 
```{r message = FALSE, warning=FALSE}
metadata$item_id=as.numeric(metadata$item_id)
metadata3=left_join(ratings, metadata)
metadata3=metadata3%>%filter(rating>=4.5)
metadata3=metadata3%>%select(user_id, title)
```

Посмотрим на пользователя с id '627711'
```{r message = FALSE, warning=FALSE}
sort_films3 = ratings %>% dplyr::filter(user_id==627711) %>% dplyr::filter(rating>=4.5)
fav_films3= metadata$title[match(sort_films3$item_id, metadata$item_id)]
fav_films3
```
Как видим, данный пользователь предпочитает фильмы в жанре боевик, драма, фантастика и мультфильмы. Предполагаем, что в рекомендации для него будет хотя бы несколько боевиков, драм, фильмов в жанре фантастика и/или мультфильмов.


```{r message = FALSE, warning=FALSE}
getFilms(627711)
```
Как можно заметить, наши прогнозы оправдались: есть драма ("Трудности перевода"), есть  фантастика ("Дитя человеческое", "Аниматрица"), что подтверждает состоятельность предложенной рекомендательной системы.

Далее сравним предпочтения и рекомендацию фильмов для пользователя '324001'
```{r message = FALSE, warning=FALSE}
sort_films3 = ratings %>% dplyr::filter(user_id==324001) %>% dplyr::filter(rating>=4.5)
fav_films3= metadata$title[match(sort_films3$item_id, metadata$item_id)]
fav_films3
```
Данные фильмы являются драмами("Shawshank Redemption", "Unforgiven") и детективом ("Glengarry Glen Ross"). Предпологаем, что среди рекомендованных фильмов в основном будут встречатся именно такие жанры.

И рекомендованными фильмами являются:
```{r message = FALSE, warning=FALSE}
getFilms(324001)
```
  
Среди предложенных фильмов встречаются драмы ("Гуд бай, Ленин!", "Список Шиндлера") и детектив (" Inside Man "). В целом, многие представленные фильмы имеют элемент драмы, что также интересует пользователя и было верно определено рекомендательной системой.


Нужно также отметить, что наша вторая рекомендательная система также может работать даже в том случае, когда в функции ничего нет:
```{r message = FALSE, warning=FALSE}
getFilms()
```
В результате чего, пользователю будут выводится наиболее популярные фильмы.


### Выводы

В ходе нашего анализа мы выполнили полный цикл анализа имеющихся данных, начиная от сетевого анализа, который изучает структуру данных и определяет сообщества внутри фильмов с различными характеристиками, и заканчивая сентимент-анализом и построением двух рекомендательных систем, демонстрирующих хорошие прогностические способности для пользователей разных категорий.

В первой части анализа мы использовали сетевой анализ для изучения структуры данных и определения сообществ внутри фильмов с различными характеристиками. Это позволило нам понять, как различные фильмы связаны между собой и какие характеристики они имеют.
Во второй части анализа мы использовали текстовый анализ для определения эмоциональной тональности текстов отзывов,  а также определения наиболее популярных тегов к фильмам. Это позволило нам понять, какие эмоции и настроения выражены в текстах и как они связаны с фильмами, а также, какие ассоциации вызывают те или иные фильмы у пользователей.
В третьей части анализа мы построили две рекомендательные системы: Collaborative Filtering и Content-based. Мы оценили эти системы на релевантность на примерах и по объективным метрикам, что дало нам неплохие результаты прогнозирования у моделей.
В ходе оценки результатов мы обнаружили, что обе рекомендательные системы демонстрируют хорошие прогностические способности для пользователей разных категорий. Мы также обнаружили, что сетевой и текстовый анализы могут быть полезен для определения рекомендаций для пользователей, не имеющих сформированных предпочтений, а также для более точного построения content-based рекомендательной системы. 


В целом, наш анализ показал, что комбинация сетевого анализа, текстового анализа и рекомендательных систем может быть полезной для понимания структуры данных и для успешного прогнозирования предпочтений потребителей. Мы также обнаружили, что эти методы могут быть полезны для создания эффективных рекомендательных систем, которые могут помочь пользователям найти фильмы, соответствующие их предпочтениям.


### Ответы на вопросы peer review

**Вопрос:** Как работает механизм рекомендации для нового пользователя?

На вход подается пустая строка ИЛИ айди пользователя, даже если его нет в системе/это новый пользователь без оцененных фильмов, на выход - список с наиболее популярными среди других пользователей фильмами, отобранных нами в ходе сетевого анализа.

*Ответ:* Пример:

```{r message = FALSE, warning=FALSE}
getFilms(11111111)
```

```{r message = FALSE, warning=FALSE}
getFilms()
```

**Вопрос:** Нормировали ли вы средние оценки фильмов в content-based системе?

*Ответ:* Если под нормировкой предполагается селекция только хороших отзывов, то да, это проводилось. Мы отбирали id фильмов с оценкой более 4, чтобы рекомендовать только относительно хорошие фильмы; затем выводили 5 фильмов, наиболее похожих на те, что оценил пользователь.

**Вопрос:** Если это  система, построенная на сентимент анализе, то я бы хотела, чтобы мне  подобрали фильм с высоким рейтингом среди фильмов с тегом love, будут ли там известные мелодрамы? 

*Ответ:* Данная система рекомендует не на основании введенного тега, а на основании вашей оценки фильмов и их тегов. 
Пример: мы нашли пользователя с высокой оценкой фильмов по тегу 'love', и вот его рекомендации:


Посмотрим на пользователя с id '933125'
```{r message = FALSE, warning=FALSE}
sort_films4 = ratings %>% dplyr::filter(user_id==933125) %>% dplyr::filter(rating>=4.5)
fav_films4= metadata$title[match(sort_films4$item_id, metadata$item_id)]
fav_films4
```
Как видим, данный пользователь действительно предпочитает мелодрамы. 

```{r message = FALSE, warning=FALSE}
getFilms(933125)
```

Здесь также есть ряд мелодрам ( "High Fidelity", "Ransom"). 

Заодно проверим еще один пример, который нам предложили на peer-review. Что выдаст система, если я укажу, что пользователю  нравятся смотреть комедии и это его любимый жанр?

Повторимся: Данная система рекомендует не на основании введенного тега, а на основании вашей оценки фильмов и их тегов. 
Пример: мы нашли пользователя с высокой оценкой фильмов по тегу 'comedy', и вот его рекомендации:

Посмотрим на пользователя с id '61246'
```{r message = FALSE, warning=FALSE}
sort_films4 = ratings %>% dplyr::filter(user_id==61246) %>% dplyr::filter(rating>=4.5)
fav_films4= metadata$title[match(sort_films4$item_id, metadata$item_id)]
fav_films4
```
Как видим, данный пользователь действительно любит комедии (здесь указаны только самые топовые фильмы, комедий, оцененных этим пользователем, на самом деле больше). 

```{r message = FALSE, warning=FALSE}
getFilms(901481)
```

Как мы видим, среди рекомендованных есть комедии (What Women Want, Cast Away), и уже просмотренные фильмы ("Fear and Loathing in Las Vegas", "The Butterfly Effect"). На просмотренность фильма мы не выствляли ограничений, поэтому пользователю данные ленты тоже попались при рекомендации. Отчасти это показывает, что рекомендации действительно попадают в таргет. 

И еще один запрос от оценивавших работу : Если пользователю нравятся фильмы ужасов, были бы ему рекомендован фильм "Крик" ("Scream")?

По тому же принципу найдем еще одного пользователя, который любит фильмы ужасов. 

```{r message = FALSE, warning=FALSE}
sort_films4 = ratings %>% dplyr::filter(user_id==838180) %>% dplyr::filter(rating>=4.5)
fav_films4= metadata$title[match(sort_films4$item_id, metadata$item_id)]
fav_films4
```
Хотелось бы отметить, что в нашем датасете очень мало "чистых" фильмов ужасов, но много пограничных случаев, как фильм "Донни Дарко" или "Лабиринт Фавна". Также это еще связано со спецификой разметки на теги, поскольку далеко не всегда тег horror принадлежит именно хоррор-фильму, но это особенности данных. 


```{r message = FALSE, warning=FALSE}
getFilms(838180)
```
Заметим, что фильмы действительно очень близки по жанру под запрос пользователя. Сам фильм "Крик" тега 'horror' не имеет, поэтому они и не пересеклись, это особенность данных. 

**Вопрос:** Что бы было, если бы я ввела несуществующий фильм

*Ответ:* Ничего, так как на вход система получает не фильмы, а ваш id. 

**Вопрос:** Если СВ система  построена по  режиссерам,  то какой список фильмов  мне предложат, если я люблю Кристофера Нолана, будет ли в этом  списке Интерстеллар или Опенгеймер?

*Ответ:* Система построена не на режиссерах, а на оценках пользователей и сентименте тегов оцененных фильмов. 

**Вопрос:** Если пользователь высоко оценил фильм "Остров Проклятых", будет ли система рекомендовать фильм "Бойцовский Клуб" и наоборот?

*Ответ:* К сожалению, в нашей выборке данных не было ни того, ни другого фильма, но, предположительно, вероятность рекомендации высокая, так как они принадлежат одному жанру и скорее всего имеют общие теги. 


**Сценарий:**  Порекомендуйте что-нибудь пользователю, которуму нравятся одновременно фильмы с высокой тональностью тэгов и в жанре "хоррор"/"ужасы" или подобные.

Продублируем пример, который мы рассматривали выше. Мы нашли любителя хорроров и фильмов смежных жанров, который активно размечал тэги и оставлял отзывы на фильмы. 

```{r message = FALSE, warning=FALSE}
sort_films4 = ratings %>% dplyr::filter(user_id==838180) %>% dplyr::filter(rating>=4.5)
fav_films4= metadata$title[match(sort_films4$item_id, metadata$item_id)]
fav_films4
```

Пользователь 838180 действительно любит хорроры, например, "Донни Дарко" или "Лабиринт фавна". В качестве рекомендации ему выведется следующее:

```{r message = FALSE, warning=FALSE}
getFilms(838180)
```

Ключевой фильм подборки - фильм "Звонок", один из самых известных хорроров. Также ему может приглянуться "Man on Fire", если он ищет что-то в жанре хоррор. 